{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")  # for final submission\n",
    "\n",
    "# Feature engineering\n",
    "df_train['Power'] = df_train['Torque [Nm]'] * df_train['Rotational speed [rpm]']\n",
    "df_train['TemperatureDifference'] = df_train['Process temperature [K]'] - df_train['Air temperature [K]']\n",
    "df_train['TemperatureVariability'] = df_train[['Air temperature [K]', 'Process temperature [K]']].std(axis=1)\n",
    "df_train['TemperatureRatio'] = df_train['Process temperature [K]'] / df_train['Air temperature [K]']\n",
    "df_train['ToolWearRate'] = df_train['Tool wear [min]'] / df_train['Tool wear [min]'].max()\n",
    "df_train['TemperatureChangeRate'] = df_train['TemperatureDifference'] / df_train['Tool wear [min]']\n",
    "df_train['TemperatureChangeRate'] = np.where(df_train['TemperatureChangeRate'] == float('inf'), 1, df_train['TemperatureChangeRate'])\n",
    "df_train['TotalFailures'] = df_train[['TWF', 'HDF', 'PWF', 'OSF', 'RNF']].sum(axis=1)\n",
    "df_train['TorqueWearRatio'] = df_train['Torque [Nm]'] / (df_train['Tool wear [min]'] + 0.0001)\n",
    "df_train['TorqueWearProduct'] = df_train['Torque [Nm]'] * df_train['Tool wear [min]']\n",
    "\n",
    "df_test['Power'] = df_test['Torque [Nm]'] * df_test['Rotational speed [rpm]']\n",
    "df_test['TemperatureDifference'] = df_test['Process temperature [K]'] - df_test['Air temperature [K]']\n",
    "df_test['TemperatureVariability'] = df_test[['Air temperature [K]', 'Process temperature [K]']].std(axis=1)\n",
    "df_test['TemperatureRatio'] = df_test['Process temperature [K]'] / df_test['Air temperature [K]']\n",
    "df_test['ToolWearRate'] = df_test['Tool wear [min]'] / df_test['Tool wear [min]'].max()\n",
    "df_test['TemperatureChangeRate'] = df_test['TemperatureDifference'] / df_test['Tool wear [min]']\n",
    "df_test['TemperatureChangeRate'] = np.where(df_test['TemperatureChangeRate'] == float('inf'), 1, df_test['TemperatureChangeRate'])\n",
    "df_test['TotalFailures'] = df_test[['TWF', 'HDF', 'PWF', 'OSF', 'RNF']].sum(axis=1)\n",
    "df_test['TorqueWearRatio'] = df_test['Torque [Nm]'] / (df_test['Tool wear [min]'] + 0.0001)\n",
    "df_test['TorqueWearProduct'] = df_test['Torque [Nm]'] * df_test['Tool wear [min]']\n",
    "\n",
    "# Feature engineering\n",
    "# df_train[\"Temperature ratio\"] = df_train['Process temperature [K]'] / df_train['Air temperature [K]']\n",
    "# df_train['Torque * Rotational speed'] = df_train['Torque [Nm]'] * df_train['Rotational speed [rpm]']\n",
    "# df_train['Torque * Tool wear'] = df_train['Torque [Nm]'] * df_train['Tool wear [min]']\n",
    "\n",
    "# df_test[\"Temperature ratio\"] = df_test['Process temperature [K]'] / df_test['Air temperature [K]']\n",
    "# df_test['Torque * Rotational speed'] = df_test['Torque [Nm]'] * df_test['Rotational speed [rpm]']\n",
    "# df_test['Torque * Tool wear'] = df_test['Torque [Nm]'] * df_test['Tool wear [min]']\n",
    "\n",
    "x_train = df_train.copy()\n",
    "x_train.drop('id', axis=1, inplace=True)\n",
    "x_train.drop('Product ID', axis=1, inplace=True)\n",
    "x_train.drop('Machine failure', axis=1, inplace=True)\n",
    "y_train = df_train[\"Machine failure\"]\n",
    "\n",
    "x_test = df_test.copy()\n",
    "x_test.drop('id', axis=1, inplace=True)\n",
    "x_test.drop('Product ID', axis=1, inplace=True)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "lm_column = 0\n",
    "\n",
    "mapping = {'L': 0.0, 'M': 0.5, 'H': 1.0}\n",
    "x_train[:, lm_column] = np.where(x_train[:, lm_column] == 'L', 0.0, np.where(x_train[:, lm_column] == 'M', 0.5, 1.0))\n",
    "x_test[:, lm_column] = np.where(x_test[:, lm_column] == 'L', 0.0, np.where(x_test[:, lm_column] == 'M', 0.5, 1.0))\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the regularized deep neural network model\n",
    "num_features = x_train.shape[1]\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005), input_shape=(num_features,)),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model on cross-validation set\n",
    "cv_predictions = model.predict(x_cv)\n",
    "cv_predictions = (cv_predictions > 0.5).astype(int)\n",
    "\n",
    "cv_accuracy = accuracy_score(y_cv, cv_predictions)\n",
    "cv_f1 = f1_score(y_cv, cv_predictions)\n",
    "cv_recall = recall_score(y_cv, cv_predictions)\n",
    "\n",
    "print(\"Cross-Validation Accuracy:\", cv_accuracy)\n",
    "print(\"Cross-Validation F1 Score:\", cv_f1)\n",
    "print(\"Cross-Validation Recall:\", cv_recall)\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = model.predict(x_test)\n",
    "# test_predictions = (test_predictions > 0.5).astype(int)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "3411/3411 [==============================] - 5s 1ms/step - loss: 0.0492 - accuracy: 0.9951\n",
      "Epoch 2/5\n",
      "3411/3411 [==============================] - 4s 1ms/step - loss: 0.0249 - accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "3411/3411 [==============================] - 4s 1ms/step - loss: 0.0240 - accuracy: 0.9962\n",
      "Epoch 4/5\n",
      "3411/3411 [==============================] - 4s 1ms/step - loss: 0.0236 - accuracy: 0.9962\n",
      "Epoch 5/5\n",
      "3411/3411 [==============================] - 4s 1ms/step - loss: 0.0234 - accuracy: 0.9962\n",
      "853/853 [==============================] - 1s 905us/step\n",
      "Cross-Validation Accuracy: 0.9961518727552591\n",
      "Cross-Validation F1 Score: 0.8648648648648648\n",
      "Cross-Validation Recall: 0.7671232876712328\n",
      "2843/2843 [==============================] - 3s 906us/step\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "indices = np.array(df_test[\"id\"], dtype=int).reshape(-1, 1)\n",
    "\n",
    "# y_test_pred = y_test_pred.reshape(-1, 1)  \n",
    "\n",
    "submission = np.hstack((indices, test_predictions))\n",
    "\n",
    "submission_df = pd.DataFrame(submission, columns=['id', 'Machine failure'])\n",
    "submission_df['id'] = submission_df['id'].astype(int)  # Convert \"id\" column to integer\n",
    "submission_df.to_csv(\"submissions/try_1.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cross-Validation Accuracy: 0.9961518727552591\n",
    "Cross-Validation F1 Score: 0.8648648648648648\n",
    "Cross-Validation Recall: 0.7671232876712328"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create LightGBM dataset\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "# Set LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': ['binary_logloss', 'auc'],\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train LightGBM model\n",
    "model = lgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "# Predict on cross-validation data (x_cv)\n",
    "cv_pred = model.predict(x_cv)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "cv_pred_binary = np.where(cv_pred >= 0.5, 1, 0)\n",
    "\n",
    "# Print evaluation metrics for cross-validation predictions\n",
    "print(\"Cross-Validation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_cv, cv_pred_binary))\n",
    "print(\"F1-Score:\", f1_score(y_cv, cv_pred_binary))\n",
    "print(\"Recall:\", recall_score(y_cv, cv_pred_binary))\n",
    "\n",
    "# Predict on test data (x_test)\n",
    "test_pred = model.predict(x_test)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-Validation Metrics:\n",
      "Accuracy: 0.995895330938943\n",
      "F1-Score: 0.8571428571428571\n",
      "Recall: 0.7671232876712328\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the cross-validation data\n",
    "y_cv_pred = gnb.predict(x_cv)\n",
    "\n",
    "# Calculate metrics for cross-validation predictions\n",
    "accuracy = accuracy_score(y_cv, y_cv_pred)\n",
    "f1 = f1_score(y_cv, y_cv_pred)\n",
    "recall = recall_score(y_cv, y_cv_pred)\n",
    "\n",
    "# Print cross-validation metrics\n",
    "print(\"Cross-validation performance:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = gnb.predict(x_test)\n",
    "\n",
    "# Print predictions for the test data\n",
    "print(\"Test data predictions:\")\n",
    "print(y_test_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-validation performance:\n",
      "Accuracy: 0.9961518727552591\n",
      "F1 score: 0.865211810012837\n",
      "Recall: 0.769406392694064\n",
      "Test data predictions:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train model\n",
    "rfc = RandomForestClassifier(n_estimators=10).fit(x_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(x_cv)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "print(\"Random Forest Classifier\", \"\\n\\tAccuracy:\", accuracy_score(y_cv, rfc_pred), \"\\n\\tF1:\", f1_score(y_cv, rfc_pred), \"\\n\\tRecall:\", recall_score(y_cv, rfc_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest Classifier \n",
      "\tAccuracy: 0.9961518727552591 \n",
      "\tF1: 0.8662420382165605 \n",
      "\tRecall: 0.776255707762557\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}